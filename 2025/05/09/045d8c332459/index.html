<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>vllm使用教程-基于qwen模型 | 爱开源GoGo</title><meta name="author" content="JimmyDing"><meta name="copyright" content="JimmyDing"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="环境搭建 创建vllm，最好单独搭建一个vllm的环境 1234conda create -n vllm python&#x3D;3.12 -yconda activate vllmpip install vllmpip show vllm # 0.8.5.post1 命令行启动vllm qwen3开源包括两款MoE模型：Qwen3-235B-A22B（2350多亿总参数、 220多亿激活参数），以及Qwe">
<meta property="og:type" content="article">
<meta property="og:title" content="vllm使用教程-基于qwen模型">
<meta property="og:url" content="https://mylofty.github.io/2025/05/09/045d8c332459/index.html">
<meta property="og:site_name" content="爱开源GoGo">
<meta property="og:description" content="环境搭建 创建vllm，最好单独搭建一个vllm的环境 1234conda create -n vllm python&#x3D;3.12 -yconda activate vllmpip install vllmpip show vllm # 0.8.5.post1 命令行启动vllm qwen3开源包括两款MoE模型：Qwen3-235B-A22B（2350多亿总参数、 220多亿激活参数），以及Qwe">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg">
<meta property="article:published_time" content="2025-05-09T06:51:21.000Z">
<meta property="article:modified_time" content="2025-05-09T07:07:51.785Z">
<meta property="article:author" content="JimmyDing">
<meta property="article:tag" content="ai">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><link rel="shortcut icon" href="/images/notebook.png"><link rel="canonical" href="https://mylofty.github.io/2025/05/09/045d8c332459/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'vllm使用教程-基于qwen模型',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-05-09 15:07:51'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/notebook.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">32</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 图库</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="爱开源GoGo"><span class="site-name">爱开源GoGo</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 图库</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">vllm使用教程-基于qwen模型</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-05-09T06:51:21.000Z" title="发表于 2025-05-09 14:51:21">2025-05-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-09T07:07:51.785Z" title="更新于 2025-05-09 15:07:51">2025-05-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/">ai</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="vllm使用教程-基于qwen模型"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>环境搭建</h1>
<p>创建vllm，最好单独搭建一个vllm的环境</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda create -n vllm python=3.12 -y</span><br><span class="line">conda activate vllm</span><br><span class="line">pip install vllm</span><br><span class="line">pip show vllm <span class="comment"># 0.8.5.post1</span></span><br></pre></td></tr></table></figure>
<h1>命令行启动vllm</h1>
<p>qwen3开源包括两款MoE模型：Qwen3-235B-A22B（2350多亿总参数、 220多亿激活参数），以及Qwen3-30B-A3B（300亿总参数、30亿激活参数）；<br>
以及六个Dense模型：Qwen3-32B、Qwen3-14B、Qwen3-8B、Qwen3-4B、Qwen3-1.7B和Qwen3-0.6B。</p>
<p>首先尝试在T4显卡（15G显存，80G内存）启动dense稠密向量的qwen3-4b模型，由于T4不支持bf16，所以需要修改为float16格式（<code>--dtype=half</code>）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve Qwen/Qwen3-4B --dtype=half</span><br></pre></td></tr></table></figure>
<p>发现跑不起来，显存太少，修改了<code>--gpu-memory-utilization=0.95 --max-model-len=16384</code>依然无法跑起来，于是用1.7B模型跑起来了</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve Qwen/Qwen3-1.7B --dtype=half</span><br></pre></td></tr></table></figure>
<p>在8卡V100上面部署 MOE模型，需要指定TP为8,type不能指定为half！</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve Qwen/Qwen3-30B-A3B --dtype=float32  --tensor-parallel-size 8</span><br></pre></td></tr></table></figure>
<h1>代码调用vllm</h1>
<p>可以直接import vllm库来进行离线推理</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入几个问题</span></span><br><span class="line">prompts = [</span><br><span class="line">    <span class="string">&quot;你好，你是谁？&quot;</span>,</span><br><span class="line">    <span class="string">&quot;法国的首都在哪里？&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置初始化采样参数</span></span><br><span class="line">sampling_params = SamplingParams(temperature=<span class="number">0.8</span>, top_p=<span class="number">0.95</span>, max_tokens=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型，确保路径正确</span></span><br><span class="line">llm = LLM(model=<span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span>, trust_remote_code=<span class="literal">True</span>, max_model_len=<span class="number">4096</span>, dtype=<span class="string">&quot;half&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示输出结果</span></span><br><span class="line">outputs = llm.generate(prompts, sampling_params)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印输出结果</span></span><br><span class="line"><span class="keyword">for</span> output <span class="keyword">in</span> outputs:</span><br><span class="line">    prompt = output.prompt</span><br><span class="line">    generated_text = output.outputs[<span class="number">0</span>].text</span><br><span class="line">    <span class="comment">#print(f&quot;Prompt: &#123;prompt!r&#125;, Generated text: &#123;generated_text!r&#125;&quot;)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Prompt: <span class="subst">&#123;prompt!r&#125;</span>, Generated text: <span class="subst">&#123;output!r&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>我们也可以暴露openai格式的http接口</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, HTTPException</span><br><span class="line"><span class="keyword">from</span> fastapi.middleware.cors <span class="keyword">import</span> CORSMiddleware</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel,Field</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span>, <span class="type">Union</span></span><br><span class="line"><span class="keyword">from</span> vllm.engine.arg_utils <span class="keyword">import</span> AsyncEngineArgs</span><br><span class="line"><span class="keyword">from</span> vllm.engine.async_llm_engine <span class="keyword">import</span> AsyncLLMEngine</span><br><span class="line"><span class="keyword">from</span> vllm.sampling_params <span class="keyword">import</span> SamplingParams</span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;OpenAI-compatible API Server&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许跨域</span></span><br><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">    allow_methods=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">    allow_headers=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化异步引擎</span></span><br><span class="line">async_engine_args = AsyncEngineArgs(</span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span>,</span><br><span class="line">    trust_remote_code=<span class="literal">True</span>,</span><br><span class="line">    max_model_len=<span class="number">4096</span>,</span><br><span class="line">    dtype=<span class="string">&quot;half&quot;</span>,</span><br><span class="line">)</span><br><span class="line">engine = AsyncLLMEngine.from_engine_args(async_engine_args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修正后的请求模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CompletionRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span> = Field(<span class="string">&quot;default-model&quot;</span>, description=<span class="string">&quot;模型名称占位符&quot;</span>)  <span class="comment"># OpenAI 格式必填字段</span></span><br><span class="line">    prompt: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="built_in">str</span>]]  <span class="comment"># 支持字符串或数组</span></span><br><span class="line">    max_tokens: <span class="built_in">int</span> = <span class="number">100</span></span><br><span class="line">    temperature: <span class="built_in">float</span> = <span class="number">0.8</span></span><br><span class="line">    top_p: <span class="built_in">float</span> = <span class="number">0.95</span></span><br><span class="line">    stream: <span class="built_in">bool</span> = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 添加其他OpenAI兼容字段</span></span><br><span class="line">    stop: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="built_in">str</span>]]] = <span class="literal">None</span></span><br><span class="line">    presence_penalty: <span class="built_in">float</span> = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Config</span>:</span><br><span class="line">        <span class="comment"># 允许接收未定义的字段（某些客户端会发送额外参数）</span></span><br><span class="line">        extra = <span class="string">&quot;allow&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 需要流式的花，调用该函数即可</span></span><br><span class="line"><span class="comment"># # 流式处理分支</span></span><br><span class="line"><span class="comment"># if request.stream:</span></span><br><span class="line"><span class="comment">#     return StreamingResponse(</span></span><br><span class="line"><span class="comment">#         generate_stream(request.prompt, sampling_params),</span></span><br><span class="line"><span class="comment">#         media_type=&quot;text/event-stream&quot;,</span></span><br><span class="line"><span class="comment">#         headers=&#123;</span></span><br><span class="line"><span class="comment">#             &#x27;Cache-Control&#x27;: &#x27;no-cache&#x27;,</span></span><br><span class="line"><span class="comment">#             &#x27;Connection&#x27;: &#x27;keep-alive&#x27;</span></span><br><span class="line"><span class="comment">#         &#125;</span></span><br><span class="line"><span class="comment">#     )</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">generate_stream</span>(<span class="params">prompt: <span class="built_in">str</span>, sampling_params: SamplingParams</span>):</span><br><span class="line">    request_id = <span class="string">&quot;stream-request-123&quot;</span></span><br><span class="line">    results_generator = engine.generate(prompt, sampling_params, request_id)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 首先生成第一个结果</span></span><br><span class="line">    first_iteration = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> request_output <span class="keyword">in</span> results_generator:</span><br><span class="line">        <span class="keyword">if</span> first_iteration:</span><br><span class="line">            first_iteration = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">continue</span>  <span class="comment"># 跳过第一个空结果</span></span><br><span class="line">        </span><br><span class="line">        text = request_output.outputs[<span class="number">0</span>].text</span><br><span class="line">        <span class="keyword">yield</span> <span class="string">f&quot;data: <span class="subst">&#123;json.dumps(&#123;</span></span></span><br><span class="line"><span class="subst"><span class="string">            <span class="string">&#x27;id&#x27;</span>: request_id,</span></span></span><br><span class="line"><span class="subst"><span class="string">            <span class="string">&#x27;object&#x27;</span>: <span class="string">&#x27;text_completion&#x27;</span>,</span></span></span><br><span class="line"><span class="subst"><span class="string">            <span class="string">&#x27;created&#x27;</span>: <span class="built_in">int</span>(time.time()),</span></span></span><br><span class="line"><span class="subst"><span class="string">            <span class="string">&#x27;choices&#x27;</span>: [&#123;</span></span></span><br><span class="line"><span class="subst"><span class="string">                <span class="string">&#x27;text&#x27;</span>: text,</span></span></span><br><span class="line"><span class="subst"><span class="string">                <span class="string">&#x27;index&#x27;</span>: <span class="number">0</span>,</span></span></span><br><span class="line"><span class="subst"><span class="string">                <span class="string">&#x27;logprobs&#x27;</span>: <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="subst"><span class="string">                <span class="string">&#x27;finish_reason&#x27;</span>: <span class="literal">None</span></span></span></span><br><span class="line"><span class="subst"><span class="string">            &#125;</span>]</span></span><br><span class="line"><span class="string">        &#125;)&#125;\n\n&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 发送结束标记</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="string">&quot;data: [DONE]\n\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/completions&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_completion</span>(<span class="params">request: CompletionRequest</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        sampling_params = SamplingParams(</span><br><span class="line">            temperature=request.temperature,</span><br><span class="line">            top_p=request.top_p,</span><br><span class="line">            max_tokens=request.max_tokens</span><br><span class="line">        )</span><br><span class="line">        request_id = <span class="string">&quot;0&quot;</span>  <span class="comment"># 简单示例，实际需生成唯一ID</span></span><br><span class="line">        results_generator = engine.generate(</span><br><span class="line">            request.prompt, sampling_params, request_id)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 非流式处理</span></span><br><span class="line">        final_output = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">for</span> request_output <span class="keyword">in</span> results_generator:</span><br><span class="line">            final_output = request_output</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;choices&quot;</span>: [&#123;</span><br><span class="line">                <span class="string">&quot;text&quot;</span>: final_output.outputs[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">&quot;index&quot;</span>: <span class="number">0</span>,</span><br><span class="line">                <span class="string">&quot;finish_reason&quot;</span>: <span class="string">&quot;length&quot;</span></span><br><span class="line">            &#125;]</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">500</span>, detail=<span class="built_in">str</span>(e))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>
<p>用curl调用如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://localhost:8000/v1/completions \</span><br><span class="line">-H &quot;Content-Type: application/json&quot; \</span><br><span class="line">-d &#x27;&#123;</span><br><span class="line">    &quot;model&quot;: &quot;your-model-name&quot;,</span><br><span class="line">    &quot;prompt&quot;: &quot;法国的首都在哪里？&quot;,</span><br><span class="line">    &quot;max_tokens&quot;: 50</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>
<h1>curl测试vllm</h1>
<ol>
<li>获取支持的模型：</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X GET http://localhost:8000/v1/models</span><br></pre></td></tr></table></figure>
<p>返回如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;object&quot;</span><span class="punctuation">:</span><span class="string">&quot;list&quot;</span><span class="punctuation">,</span><span class="attr">&quot;data&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span><span class="punctuation">,</span><span class="attr">&quot;object&quot;</span><span class="punctuation">:</span><span class="string">&quot;model&quot;</span><span class="punctuation">,</span><span class="attr">&quot;created&quot;</span><span class="punctuation">:</span><span class="number">1746610595</span><span class="punctuation">,</span><span class="attr">&quot;owned_by&quot;</span><span class="punctuation">:</span><span class="string">&quot;vllm&quot;</span><span class="punctuation">,</span><span class="attr">&quot;root&quot;</span><span class="punctuation">:</span><span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span><span class="punctuation">,</span><span class="attr">&quot;parent&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;max_model_len&quot;</span><span class="punctuation">:</span><span class="number">40960</span><span class="punctuation">,</span><span class="attr">&quot;permission&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;modelperm-a2b3973921cc44a99947865b1baee7cc&quot;</span><span class="punctuation">,</span><span class="attr">&quot;object&quot;</span><span class="punctuation">:</span><span class="string">&quot;model_permission&quot;</span><span class="punctuation">,</span><span class="attr">&quot;created&quot;</span><span class="punctuation">:</span><span class="number">1746610595</span><span class="punctuation">,</span><span class="attr">&quot;allow_create_engine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;allow_sampling&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;allow_logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;allow_search_indices&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;allow_view&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;allow_fine_tuning&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;organization&quot;</span><span class="punctuation">:</span><span class="string">&quot;*&quot;</span><span class="punctuation">,</span><span class="attr">&quot;group&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;is_blocking&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>调用模型进行问答，关闭推理<br>
Qwen3 模型会在回复前进行思考。这种行为可以通过硬开关（完全禁用思考）或软开关（模型遵循用户关于是否应该思考的指令）来控制。</li>
</ol>
<p>硬开关在 vLLM 中可以通过以下 API 调用配置使用。要禁用思考，请使用<code>&quot;chat_template_kwargs&quot;: &#123;&quot;enable_thinking&quot;: false&#125;</code>参数</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions -H <span class="string">&quot;Content-Type: application/json&quot;</span> -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;Qwen/Qwen3-1.7B&quot;,</span></span><br><span class="line"><span class="string">  &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">    &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;介绍一下这个qwen3模型吧，不要思考&quot;&#125;</span></span><br><span class="line"><span class="string">  ],</span></span><br><span class="line"><span class="string">  &quot;temperature&quot;: 0.6,</span></span><br><span class="line"><span class="string">  &quot;top_p&quot;: 0.95,</span></span><br><span class="line"><span class="string">  &quot;top_k&quot;: 20,</span></span><br><span class="line"><span class="string">  &quot;max_tokens&quot;: 32768,</span></span><br><span class="line"><span class="string">  &quot;chat_template_kwargs&quot;: &#123;&quot;enable_thinking&quot;: false&#125;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>返回如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;chatcmpl-db7f824768084631b9eb0e8a0094d004&quot;</span><span class="punctuation">,</span><span class="attr">&quot;object&quot;</span><span class="punctuation">:</span><span class="string">&quot;chat.completion&quot;</span><span class="punctuation">,</span><span class="attr">&quot;created&quot;</span><span class="punctuation">:</span><span class="number">1746610895</span><span class="punctuation">,</span><span class="attr">&quot;model&quot;</span><span class="punctuation">:</span><span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span><span class="punctuation">,</span><span class="attr">&quot;choices&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;message&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span><span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span><span class="attr">&quot;reasoning_content&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span><span class="string">&quot;&lt;think&gt;\n&lt;/think&gt;\n\nQwen3 是通义实验室研发的大型语言模型，属于通义千问系列。它在多个方面进行了优化和升级，包括但不限于：\n\n1. **参数量和计算能力**：Qwen3 拥有更大的参数量，能够处理更复杂的语言任务，同时在计算效率上也有提升。\n\n2. **多语言支持**：Qwen3 支持多种语言，能够进行跨语言的理解和生成，这使得它在多语言应用场景中更具优势。\n\n3. **指令遵循能力**：Qwen3 在遵循指令和执行任务方面表现优异，能够处理各种复杂的指令，包括多轮对话和任务执行。\n\n4. **上下文长度**：Qwen3 的上下文长度更长，能够处理更长的对话历史，从而提供更连贯和准确的回答。\n\n5. **多模态能力**：虽然 Qwen3 主要专注于文本处理，但它的多模态能力也在不断提升，能够处理图像、音频等多媒体信息。\n\n6. **安全性与可靠性**：Qwen3 在安全性方面进行了加强，确保模型在使用过程中不会产生有害或不适当的内容。\n\nQwen3 的这些改进使其在多个领域，如客服、内容创作、教育、科研等，都具有广泛的应用前景。如果你有具体的应用场景或问题，可以告诉我，我可以提供更详细的介绍。&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tool_calls&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;finish_reason&quot;</span><span class="punctuation">:</span><span class="string">&quot;stop&quot;</span><span class="punctuation">,</span><span class="attr">&quot;stop_reason&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;prompt_tokens&quot;</span><span class="punctuation">:</span><span class="number">18</span><span class="punctuation">,</span><span class="attr">&quot;total_tokens&quot;</span><span class="punctuation">:</span><span class="number">309</span><span class="punctuation">,</span><span class="attr">&quot;completion_tokens&quot;</span><span class="punctuation">:</span><span class="number">291</span><span class="punctuation">,</span><span class="attr">&quot;prompt_tokens_details&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;prompt_logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>硬开关在 vLLM 中可以通过以下 API 调用配置使用。要禁用思考，请使用<code>&quot;chat_template_kwargs&quot;: &#123;&quot;enable_thinking&quot;: false&#125;</code>参数</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions -H <span class="string">&quot;Content-Type: application/json&quot;</span> -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;Qwen/Qwen3-1.7B&quot;,</span></span><br><span class="line"><span class="string">  &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">    &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;介绍一下这个qwen3模型吧&quot;&#125;</span></span><br><span class="line"><span class="string">  ],</span></span><br><span class="line"><span class="string">  &quot;temperature&quot;: 0.6,</span></span><br><span class="line"><span class="string">  &quot;top_p&quot;: 0.95,</span></span><br><span class="line"><span class="string">  &quot;top_k&quot;: 20,</span></span><br><span class="line"><span class="string">  &quot;max_tokens&quot;: 32768,</span></span><br><span class="line"><span class="string">  &quot;chat_template_kwargs&quot;: &#123;&quot;enable_thinking&quot;: false&#125;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>返回如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;chatcmpl-b45919d5eb6745c686a1017f92a64e12&quot;</span><span class="punctuation">,</span><span class="attr">&quot;object&quot;</span><span class="punctuation">:</span><span class="string">&quot;chat.completion&quot;</span><span class="punctuation">,</span><span class="attr">&quot;created&quot;</span><span class="punctuation">:</span><span class="number">1746612269</span><span class="punctuation">,</span><span class="attr">&quot;model&quot;</span><span class="punctuation">:</span><span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span><span class="punctuation">,</span><span class="attr">&quot;choices&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;message&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span><span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span><span class="attr">&quot;reasoning_content&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span><span class="string">&quot;Qwen3 是通义实验室研发的一系列大语言模型之一，属于通义千问系列。它是在 Qwen2 的基础上进行优化和升级的版本，具有更强的性能和更丰富的功能。\n\nQwen3 模型在以下几个方面进行了改进：\n\n1. **参数量更大**：Qwen3 的参数量比 Qwen2 更大，从而能够更好地理解和生成自然语言。\n\n2. **训练数据更全面**：Qwen3 采用了更丰富的训练数据，覆盖了更多领域和语言风格，使得模型在多样化的任务上表现更好。\n\n3. **性能提升**：在多个基准测试中，Qwen3 的性能显著优于 Qwen2，特别是在生成文本、理解任务和多语言支持等方面。\n\n4. **功能增强**：Qwen3 支持更多的功能，比如更精细的文本生成、更强的推理能力、更好的对话交互体验等。\n\n5. **多语言支持**：Qwen3 支持多种语言的处理，包括中文、英文、日文、韩文等，使得模型在多语言场景下更具适应性。\n\nQwen3 适用于多种应用场景，如客服、内容创作、教育、科研等，能够提供更精准、更自然的交互体验。\n\n如果你有具体的问题或需要进一步了解某个方面，欢迎继续提问！&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tool_calls&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;finish_reason&quot;</span><span class="punctuation">:</span><span class="string">&quot;stop&quot;</span><span class="punctuation">,</span><span class="attr">&quot;stop_reason&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;prompt_tokens&quot;</span><span class="punctuation">:</span><span class="number">22</span><span class="punctuation">,</span><span class="attr">&quot;total_tokens&quot;</span><span class="punctuation">:</span><span class="number">303</span><span class="punctuation">,</span><span class="attr">&quot;completion_tokens&quot;</span><span class="punctuation">:</span><span class="number">281</span><span class="punctuation">,</span><span class="attr">&quot;prompt_tokens_details&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;prompt_logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<ol start="3">
<li>调用模型问答，格式化推理<br>
默认情况下模型推理会输出在content里面，如下所示：</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;chatcmpl-93778bd8c9ef48b48d189f1530edd9a3&quot;</span><span class="punctuation">,</span><span class="attr">&quot;object&quot;</span><span class="punctuation">:</span><span class="string">&quot;chat.completion&quot;</span><span class="punctuation">,</span><span class="attr">&quot;created&quot;</span><span class="punctuation">:</span><span class="number">1746610826</span><span class="punctuation">,</span><span class="attr">&quot;model&quot;</span><span class="punctuation">:</span><span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span><span class="punctuation">,</span><span class="attr">&quot;choices&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;message&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span><span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span><span class="attr">&quot;reasoning_content&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span><span class="string">&quot;&lt;think&gt;\n嗯，用户让我介绍一下Qwen3模型。首先，我需要确认用户对Qwen系列模型的了解程度。Qwen系列是通义实验室开发的大型语言模型，Qwen3是其中最新版本，可能在性能、功能或架构上有改进。\n\n用户可能想知道Qwen3的主要特点，比如参数量、训练数据、应用场景，或者它与其他模型的区别。我需要确保信息准确，同时避免过于技术化的术语，保持易懂。\n\n另外，用户可能对Qwen3的更新有哪些具体改进感兴趣，比如是否在多语言支持、推理速度、生成质量等方面有提升。还要考虑用户可能的深层需求，比如他们是否在使用Qwen3进行特定任务，需要了解其优势。\n\n需要注意的是，Qwen3可能在2023年或之后发布，但具体细节可能需要查阅官方资料。如果有不确定的地方，应该指出需要参考官方文档或最新公告。同时，要确保回答结构清晰，分点说明，让用户容易理解。\n\n最后，保持回答的友好和专业，避免使用过于复杂的术语，确保信息全面且易于消化。可能还需要提醒用户如果需要更详细的信息，可以提供更具体的方面，比如应用场景或技术细节。\n&lt;/think&gt;\n\nQwen3是通义实验室推出的最新一代大型语言模型，基于通义千问系列的最新研究成果，旨在提升模型的多语言理解、生成、推理能力以及与人类的交互体验。以下是关于Qwen3的一些关键信息：\n\n---\n\n### **1. 模型基础**\n- **参数量**：Qwen3的参数量显著增加，相比前代模型（如Qwen2）提升了约2倍，使得模型在处理复杂任务时更具能力。\n- **训练数据**：基于海量多语言文本数据（包括但不限于书籍、论文、网页、对话等），覆盖全球范围的多样化内容。\n- **训练方式**：采用自监督学习和监督学习结合的方式，通过大规模数据预训练和微调优化模型性能。\n\n---\n\n### **2. 核心能力**\n- **多语言支持**：支持16种主流语言（如中文、英文、日语、韩语、西班牙语等），能够处理跨语言的翻译、问答、代码生成等任务。\n- **高质量生成**：在文本生成、对话交互、代码编写、逻辑推理等方面表现优异，能够生成流畅、自然、符合语境的文本。\n- **推理能力**：具备强大的逻辑推理能力，能够处理复杂问题，如数学计算、逻辑推导、因果关系分析等。\n- **上下文理解**：支持长文本处理，能够理解并生成连贯的多段对话或长篇内容。\n\n---\n\n### **3. 与前代模型的对比**\n- **Qwen3**：\n  - **参数量**：比Qwen2大约2倍，模型容量更大。\n  - **性能提升**：在多个基准测试中（如GLUE、SQuAD、CodeXGLUE等）表现优于前代模型。\n  - **效率优化**：在保持高性能的同时，优化了推理速度，适合实时应用场景。\n- **Qwen2**：\n  - 早期版本，参数量约为70亿，性能在多语言和复杂任务上有所提升，但相比Qwen3仍有差距。\n\n---\n\n### **4. 应用场景**\n- **内容创作**：如文章撰写、故事生成、诗歌创作等。\n- **代码生成**：支持多种编程语言（如Python、Java、C++等）的代码编写。\n- **对话交互**：用于客服、智能助手、教育辅导等场景。\n- **多语言支持**：适合需要跨语言服务的全球化业务（如翻译、客服、国际教育等）。\n- **推理任务**：如数学问题解答、逻辑推理、因果分析等。\n\n---\n\n### **5. 技术特点**\n- **模型架构**：基于Transformer架构，采用多层Transformer编码器和解码器结构。\n- **训练策略**：结合自监督学习（如掩码语言模型）和监督学习（如任务特定的微调）。\n- **优化技术**：引入了高效的训练和推理优化技术，减少计算资源消耗。\n\n---\n\n### **6. 未来方向**\n- **持续迭代**：Qwen3是通义实验室持续优化和迭代的成果，后续可能推出更多版本（如Qwen4）。\n- **开放生态**：可能提供API接口，支持开发者集成到各类应用中。\n\n---\n\n### **注意事项**\n- **具体细节**：Qwen3的具体技术细节（如参数量、训练数据规模、优化方法等）可能需要参考官方文档或最新公告。\n- **适用场景**：建议根据实际需求选择合适的版本（如Qwen3的多语言能力是否满足需求）。\n\n---\n\n如果你有特定的应用场景或技术问题，可以进一步说明，我可以提供更针对性的分析！&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tool_calls&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;finish_reason&quot;</span><span class="punctuation">:</span><span class="string">&quot;stop&quot;</span><span class="punctuation">,</span><span class="attr">&quot;stop_reason&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;prompt_tokens&quot;</span><span class="punctuation">:</span><span class="number">15</span><span class="punctuation">,</span><span class="attr">&quot;total_tokens&quot;</span><span class="punctuation">:</span><span class="number">1051</span><span class="punctuation">,</span><span class="attr">&quot;completion_tokens&quot;</span><span class="punctuation">:</span><span class="number">1036</span><span class="punctuation">,</span><span class="attr">&quot;prompt_tokens_details&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;prompt_logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>我们希望模型能够将推理过程结构化解析到<code>reasoning_content</code>里面，为此，vllm启动模型时需要修改参数：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve Qwen/Qwen3-1.7B --dtype=half --enable-reasoning --reasoning-parser deepseek_r1</span><br></pre></td></tr></table></figure>
<p>发送问题</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions -H <span class="string">&quot;Content-Type: application/json&quot;</span> -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;Qwen/Qwen3-1.7B&quot;,</span></span><br><span class="line"><span class="string">  &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">    &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;介绍一下这个qwen3模型吧&quot;&#125;</span></span><br><span class="line"><span class="string">  ],</span></span><br><span class="line"><span class="string">  &quot;temperature&quot;: 0.6,</span></span><br><span class="line"><span class="string">  &quot;top_p&quot;: 0.95,</span></span><br><span class="line"><span class="string">  &quot;top_k&quot;: 20,</span></span><br><span class="line"><span class="string">  &quot;max_tokens&quot;: 32768</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>这样便能将推理过程分开</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;chatcmpl-c85e18f541634e9d9a98c4bf07bc06c0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;object&quot;</span><span class="punctuation">:</span><span class="string">&quot;chat.completion&quot;</span><span class="punctuation">,</span><span class="attr">&quot;created&quot;</span><span class="punctuation">:</span><span class="number">1746616790</span><span class="punctuation">,</span><span class="attr">&quot;model&quot;</span><span class="punctuation">:</span><span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span><span class="punctuation">,</span><span class="attr">&quot;choices&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;message&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span><span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span><span class="attr">&quot;reasoning_content&quot;</span><span class="punctuation">:</span><span class="string">&quot;\n嗯，用户让我介绍一下Qwen3模型。首先，我需要确认Qwen3是否真的存在，因为之前我可能没有接触过这个模型。可能用户是想问Qwen系列中的某个版本，比如Qwen2或者Qwen3。不过根据我的知识库，Qwen系列是通义实验室研发的，目前最新的是Qwen2，而Qwen3可能是一个后续的版本，但不确定是否有官方发布。\n\n接下来，我需要考虑用户可能的背景。他们可能对大模型技术感兴趣，或者在寻找特定的应用场景，比如对话、代码生成、多语言支持等。用户可能没有明确说明，但需要我提供全面的信息，包括模型的架构、性能、应用场景、优势等。\n\n然后，我要确保信息的准确性。如果Qwen3确实存在，我需要查找相关资料，比如官方文档或技术博客，确认其特点，比如参数量、训练数据、技术架构（如Transformer结构）、性能指标（如推理速度、参数量、训练数据量）等。同时，要提到其在不同任务上的表现，比如文本生成、代码生成、多语言支持、推理效率等。\n\n另外，用户可能关心Qwen3是否支持多语言，是否有特别的优化，比如支持中文、英文、日文等，或者是否有特定的行业应用，比如金融、医疗、教育等。此外，可能还需要提到模型的训练方式，比如是否使用了大规模数据，是否进行了微调，或者是否有特定的训练策略。\n\n还要注意潜在的问题，比如Qwen3是否已经发布，是否有公开的论文或技术文档，是否需要特定的环境或工具来使用。如果Qwen3是尚未发布的版本，可能需要说明当前的进展，或者建议用户关注官方渠道获取最新信息。\n\n最后，确保回答结构清晰，分点说明，涵盖关键点，如模型架构、性能、应用场景、优势、未来展望等，同时保持语言简洁易懂，避免使用过于专业的术语，除非必要。同时，提醒用户如果有具体需求，可以进一步询问，以便提供更针对性的信息。\n&quot;</span><span class="punctuation">,</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span><span class="string">&quot;\n\nQwen3 是通义实验室研发的大型语言模型系列中的最新版本，属于通义千问（Qwen）系列的后续迭代。根据目前公开信息，Qwen3 作为通义千问的最新版本，具备以下特点和优势：\n\n---\n\n### **1. 模型架构与参数**\n- **参数量**：Qwen3 的参数量显著增加，相比前代模型（如 Qwen2）提升了数十倍，具体数值需参考官方发布。\n- **训练数据**：基于大规模多语言文本数据训练，支持中文、英文、日文、韩语等多语言任务。\n- **技术架构**：采用 **Transformer** 基础架构，结合 **多模态**（如图像、视频）和 **多语言** 的优化策略，提升跨语言理解能力。\n\n---\n\n### **2. 核心能力**\n- **文本生成**：支持高质量的自然语言生成，包括对话、写作、代码编写等，能够生成连贯、逻辑性强的文本。\n- **多语言支持**：在中文、英文、日文、韩语等多语言任务中表现优异，支持跨语言对话和翻译。\n- **代码生成**：具备强大的代码生成能力，可编写多种编程语言（如 Python、Java、C++ 等）的代码。\n- **推理效率**：通过优化模型结构和推理流程，显著提升推理速度，降低计算资源消耗。\n\n---\n\n### **3. 应用场景**\n- **通用对话**：适用于客服、虚拟助手等场景，支持多轮对话和复杂问题解答。\n- **代码开发**：辅助开发者编写代码、调试和优化，提升开发效率。\n- **多语言翻译**：支持实时翻译和跨语言文本理解，适用于国际业务场景。\n- **内容创作**：生成新闻、文章、故事等文本内容，满足不同需求。\n\n---\n\n### **4. 优势与改进**\n- **更强大的多语言能力**：相比 Qwen2，Qwen3 在多语言任务中表现更优，支持更多语言和更复杂的语境理解。\n- **更高的推理效率**：通过模型压缩和优化技术，降低推理延迟，提升实际应用中的响应速度。\n- **更丰富的应用场景**：结合行业需求，优化特定领域的任务（如金融、医疗、教育等）。\n\n---\n\n### **5. 未来展望**\n- **持续优化**：通义实验室将持续迭代 Qwen3，结合最新研究进展，进一步提升模型性能。\n- **开放生态**：可能提供 API 接口或开发工具，支持开发者集成到各类应用中。\n\n---\n\n### **注意事项**\n- **版本信息**：目前 Qwen3 是否已正式发布需以官方公告为准。若尚未发布，可能需关注通义千问系列的更新动态。\n- **技术细节**：具体参数、训练数据量、技术细节等需参考官方文档或技术白皮书。\n\n---\n\n如需进一步了解 Qwen3 的具体技术细节或应用场景，建议关注通义实验室的官方渠道（如官网、技术博客、GitHub 仓库等）获取最新信息。如果你有特定需求（如代码生成、多语言支持等），也可以告诉我，我可以提供更针对性的建议！&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tool_calls&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;finish_reason&quot;</span><span class="punctuation">:</span><span class="string">&quot;stop&quot;</span><span class="punctuation">,</span><span class="attr">&quot;stop_reason&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;prompt_tokens&quot;</span><span class="punctuation">:</span><span class="number">15</span><span class="punctuation">,</span><span class="attr">&quot;total_tokens&quot;</span><span class="punctuation">:</span><span class="number">1135</span><span class="punctuation">,</span><span class="attr">&quot;completion_tokens&quot;</span><span class="punctuation">:</span><span class="number">1120</span><span class="punctuation">,</span><span class="attr">&quot;prompt_tokens_details&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;prompt_logprobs&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h1>vllm函数调用</h1>
<p>vllm的函数调用是基于transformers的分词器来实现函数的格式化输入，同时vllm实现了辅助函数实现函数参数的解析。</p>
<p>我们先来看一下transformers的tokenizer是如何进行函数的格式化输入的</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> tools <span class="keyword">import</span> *</span><br><span class="line">model_name_or_path = <span class="string">&quot;Qwen/Qwen3-1.7B&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    model_name_or_path,</span><br><span class="line">    torch_dtype=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">)</span><br><span class="line">tools = TOOLS</span><br><span class="line">messages = MESSAGES[:]</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template(messages, tools=tools, add_generation_prompt=<span class="literal">True</span>, tokenize=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(text)</span><br><span class="line">inputs = tokenizer(text, return_tensors=<span class="string">&quot;pt&quot;</span>).to(model.device)</span><br><span class="line">outputs = model.generate(**inputs, max_new_tokens=<span class="number">512</span>)</span><br><span class="line">output_text = tokenizer.batch_decode(outputs)[<span class="number">0</span>][<span class="built_in">len</span>(text):]</span><br></pre></td></tr></table></figure>
<p>tokenizer会读取模型<code>tokenizer_config.json</code>中的<code>chat_prompt</code>聊天模板来将函数参数进行转换，它利用<code>Jinja</code>模板引擎隐藏了构建模型输入的复杂性。</p>
<ol>
<li><code>apply_chat_template</code>内部调用<code>render_jinja_template</code>函数来解析<code>jinja</code>模板</li>
<li>编译<code>tokenizer_config.json</code>中的<code>chat_prompt</code></li>
<li>将tools转换为json格式</li>
<li>使用编译好的聊天模板，将用户messages和json语法的工具替换到聊天模板中</li>
</ol>
<p>qwen的聊天模板中包含了对 Hermes 风格工具调用的支持,<code>chat_prompt</code>如下</p>
<figure class="highlight jinja"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> tools %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_start|&gt;system\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> messages[0].role == &#x27;system&#x27; %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- messages[0].content + &#x27;\\n\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-variable">&#123;&#123;- \&quot;# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:\\n&lt;tools&gt;\&quot; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">for</span></span> tool <span class="keyword">in</span> tools %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- \&quot;\\n\&quot; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- tool | tojson &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endfor</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-variable">&#123;&#123;- \&quot;\\n&lt;/tools&gt;\\n\\nFor each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:\\n&lt;tool_call&gt;\\n&#123;\\\&quot;name\\\&quot;: &lt;function-name&gt;, \\\&quot;arguments\\\&quot;: &lt;args-json-object&gt;&#125;\\n&lt;/tool_call&gt;&lt;|im_end|&gt;\\n\&quot; &#125;&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> messages[0].role == &#x27;system&#x27; %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_start|&gt;system\\n&#x27; + messages[0].content + &#x27;&lt;|im_end|&gt;\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name">set</span> ns = namespace(multi_step_tool=true, last_query_index=messages|<span class="name">length</span> - 1) %&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name"><span class="name">for</span></span> message <span class="keyword">in</span> messages[::-1] %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name">set</span> index = (messages|<span class="name">length</span> - 1) - loop.index0 %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> ns.multi_step_tool and message.role == \&quot;user\&quot; and not(message.content.startswith(&#x27;&lt;tool_response&gt;&#x27;) and message.content.endswith(&#x27;&lt;/tool_response&gt;&#x27;)) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name">set</span> ns.multi_step_tool = false %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name">set</span> ns.last_query_index = index %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name"><span class="name">endfor</span></span> %&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name"><span class="name">for</span></span> message <span class="keyword">in</span> messages %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> (message.role == \&quot;user\&quot;) or (message.role == \&quot;system\&quot; and not loop.first) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\\n&#x27; + message.content + &#x27;&lt;|im_end|&gt;&#x27; + &#x27;\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">elif</span></span> message.role == \&quot;assistant\&quot; %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name">set</span> content = message.content %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name">set</span> reasoning_content = &#x27;&#x27; %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> message.reasoning_content is defined and message.reasoning_content is not none %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-tag">&#123;%- <span class="name">set</span> reasoning_content = message.reasoning_content %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> &#x27;&lt;/think&gt;&#x27; <span class="keyword">in</span> message.content %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name">set</span> content = message.content.split(&#x27;&lt;/think&gt;&#x27;)[-1].lstrip(&#x27;\\n&#x27;) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name">set</span> reasoning_content = message.content.split(&#x27;&lt;/think&gt;&#x27;)[0].rstrip(&#x27;\\n&#x27;).split(&#x27;&lt;think&gt;&#x27;)[-1].lstrip(&#x27;\\n&#x27;) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> loop.index0 &gt; ns.last_query_index %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> loop.last or (not loop.last and reasoning_content) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\\n&lt;think&gt;\\n&#x27; + reasoning_content.strip(&#x27;\\n&#x27;) + &#x27;\\n&lt;/think&gt;\\n\\n&#x27; + content.lstrip(&#x27;\\n&#x27;) &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-tag">&#123;%- <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\\n&#x27; + content &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\\n&#x27; + content &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> message.tool_calls %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-tag">&#123;%- <span class="name"><span class="name">for</span></span> tool_call <span class="keyword">in</span> message.tool_calls %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> (loop.first and content) or (not loop.first) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">                  </span><span class="template-variable">&#123;&#123;- &#x27;\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> tool_call.function %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">                  </span><span class="template-tag">&#123;%- <span class="name">set</span> tool_call = tool_call.function %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-variable">&#123;&#123;- &#x27;&lt;tool_call&gt;\\n&#123;\&quot;name\&quot;: \&quot;&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-variable">&#123;&#123;- tool_call.name &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-variable">&#123;&#123;- &#x27;\&quot;, \&quot;arguments\&quot;: &#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> tool_call.arguments is string %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">                  </span><span class="template-variable">&#123;&#123;- tool_call.arguments &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">                  </span><span class="template-variable">&#123;&#123;- tool_call.arguments | tojson &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-variable">&#123;&#123;- &#x27;&#125;\\n&lt;/tool_call&gt;&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endfor</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_end|&gt;\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">elif</span></span> message.role == \&quot;tool\&quot; %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> loop.first or (messages[loop.index0 - 1].role != \&quot;tool\&quot;) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_start|&gt;user&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- &#x27;\\n&lt;tool_response&gt;\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- message.content &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- &#x27;\\n&lt;/tool_response&gt;&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> loop.last or (messages[loop.index0 + 1].role != \&quot;tool\&quot;) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_end|&gt;\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name"><span class="name">endfor</span></span> %&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> add_generation_prompt %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-variable">&#123;&#123;- &#x27;&lt;|im_start|&gt;assistant\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> enable_thinking is defined and enable_thinking is false %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      </span><span class="template-variable">&#123;&#123;- &#x27;&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n&#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml">\n</span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span></span><br></pre></td></tr></table></figure>
<p>经过<code>jinja</code>模板的编译，我们可以看到输出的文本如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;|im_start|&gt;system</span><br><span class="line">You are Qwen, created by Alibaba Cloud. You are a helpful assistant.</span><br><span class="line"></span><br><span class="line">Current Date: 2024-09-30</span><br><span class="line"></span><br><span class="line"># Tools</span><br><span class="line"></span><br><span class="line">You may call one or more functions to assist with the user query.</span><br><span class="line"></span><br><span class="line">You are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:</span><br><span class="line">&lt;tools&gt;</span><br><span class="line">&#123;&quot;type&quot;: &quot;function&quot;, &quot;function&quot;: &#123;&quot;name&quot;: &quot;get_current_temperature&quot;, &quot;description&quot;: &quot;Get current temperature at a location.&quot;, &quot;parameters&quot;: &#123;&quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: &#123;&quot;location&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;The location to get the temperature for, in the format \&quot;City, State, Country\&quot;.&quot;&#125;, &quot;unit&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;enum&quot;: [&quot;celsius&quot;, &quot;fahrenheit&quot;], &quot;description&quot;: &quot;The unit to return the temperature in. Defaults to \&quot;celsius\&quot;.&quot;&#125;&#125;, &quot;required&quot;: [&quot;location&quot;]&#125;&#125;&#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;function&quot;, &quot;function&quot;: &#123;&quot;name&quot;: &quot;get_temperature_date&quot;, &quot;description&quot;: &quot;Get temperature at a location and date.&quot;, &quot;parameters&quot;: &#123;&quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: &#123;&quot;location&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;The location to get the temperature for, in the format \&quot;City, State, Country\&quot;.&quot;&#125;, &quot;date&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;The date to get the temperature for, in the format \&quot;Year-Month-Day\&quot;.&quot;&#125;, &quot;unit&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;enum&quot;: [&quot;celsius&quot;, &quot;fahrenheit&quot;], &quot;description&quot;: &quot;The unit to return the temperature in. Defaults to \&quot;celsius\&quot;.&quot;&#125;&#125;, &quot;required&quot;: [&quot;location&quot;, &quot;date&quot;]&#125;&#125;&#125;</span><br><span class="line">&lt;/tools&gt;</span><br><span class="line"></span><br><span class="line">For each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:</span><br><span class="line">&lt;tool_call&gt;</span><br><span class="line">&#123;&quot;name&quot;: &lt;function-name&gt;, &quot;arguments&quot;: &lt;args-json-object&gt;&#125;</span><br><span class="line">&lt;/tool_call&gt;&lt;|im_end|&gt;</span><br><span class="line">&lt;|im_start|&gt;user</span><br><span class="line">What&#x27;s the temperature in San Francisco now? How about tomorrow?&lt;|im_end|&gt;</span><br><span class="line">&lt;|im_start|&gt;assistant</span><br></pre></td></tr></table></figure>
<p>模型最终推理结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;think&gt;</span><br><span class="line">Okay, the user is asking for the current temperature in San Francisco and the temperature tomorrow. Let me check the available functions.</span><br><span class="line"></span><br><span class="line">There&#x27;s get_current_temperature which requires a location and unit. The user didn&#x27;t specify the unit, so I&#x27;ll default to celsius. Then, for tomorrow&#x27;s temperature, I need to use get_temperature_date. The date parameter should be in Year-Month-Day format. Since today is September 30, 2024, tomorrow would be October 1, 2024. </span><br><span class="line"></span><br><span class="line">Wait, the user didn&#x27;t specify the unit for tomorrow, but the current one is default. I should probably mention both units if possible, but the functions might not support that. Let me check the function parameters again. The unit is optional for get_current_temperature, and the default is celsius. For get_temperature_date, the unit is optional with default celsius. So I can call both functions with the default unit.</span><br><span class="line"></span><br><span class="line">So first, call get_current_temperature with location &quot;San Francisco&quot; and unit celsius. Then, call get_temperature_date with location &quot;San Francisco&quot;, date &quot;2024-10-01&quot;, and unit celsius. Then provide both results to the user.</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">&lt;tool_call&gt;</span><br><span class="line">&#123;&quot;name&quot;: &quot;get_current_temperature&quot;, &quot;arguments&quot;: &#123;&quot;location&quot;: &quot;San Francisco&quot;&#125;&#125;</span><br><span class="line">&lt;/tool_call&gt;</span><br><span class="line">&lt;tool_call&gt;</span><br><span class="line">&#123;&quot;name&quot;: &quot;get_temperature_date&quot;, &quot;arguments&quot;: &#123;&quot;location&quot;: &quot;San Francisco&quot;, &quot;date&quot;: &quot;2024-10-01&quot;&#125;&#125;</span><br><span class="line">&lt;/tool_call&gt;&lt;|im_end|&gt;</span><br></pre></td></tr></table></figure>
<p>由于这种格式的模型输出没有进行切分，为此，使用vllm进行部署时，可以让vllm按hermes规则将模型的输出进行进行到tool_call里面</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve Qwen/Qwen3-1.7B --dtype half --enable-auto-tool-choice --tool-call-parser hermes</span><br></pre></td></tr></table></figure>
<p>回答如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ChatCompletion(id=&#x27;chatcmpl-a8b1586cc7cf4bbc849787e85f40805b&#x27;<span class="punctuation">,</span> choices=<span class="punctuation">[</span>Choice(finish_reason=&#x27;tool_calls&#x27;<span class="punctuation">,</span> index=<span class="number">0</span><span class="punctuation">,</span> logprobs=None<span class="punctuation">,</span> message=ChatCompletionMessage(content=&#x27;&lt;think&gt;\nOkay<span class="punctuation">,</span> let me see. The user is asking for the current temperature in San Francisco and the temperature tomorrow. So I need to use the available functions.\n\nFirst<span class="punctuation">,</span> the current temperature. There\&#x27;s the get_current_temperature function. It requires the location and unit. The user didn\&#x27;t specify the unit<span class="punctuation">,</span> so I\&#x27;ll default to celsius. So I\&#x27;ll call that function with location <span class="string">&quot;San Francisco&quot;</span> and unit <span class="string">&quot;celsius&quot;</span>.\n\nThen<span class="punctuation">,</span> for tomorrow\&#x27;s temperature<span class="punctuation">,</span> I need the get_temperature_date function. The parameters are location<span class="punctuation">,</span> date<span class="punctuation">,</span> and unit. The date is tomorrow<span class="punctuation">,</span> which would be <span class="number">2024</span><span class="number">-10</span><span class="number">-01</span> if today is September <span class="number">30.</span> Wait<span class="punctuation">,</span> but the current date is <span class="number">2024</span><span class="number">-09</span><span class="number">-30.</span> So tomorrow would be <span class="number">2024</span><span class="number">-10</span><span class="number">-01.</span> I\&#x27;ll set the date to that and keep the unit as celsius again. \n\nWait<span class="punctuation">,</span> the user might not care about the unit<span class="punctuation">,</span> but since the first function uses celsius by default<span class="punctuation">,</span> maybe I should stick with that. But the second one can also use celsius. So I\&#x27;ll make two separate calls<span class="punctuation">:</span> one for current and one for tomorrow\&#x27;s date.\n\nI need to check if the date format is correct. The date parameter should be in Year-Month-Day format. So <span class="number">2024</span><span class="number">-10</span><span class="number">-01</span> is correct. \n\nSo the tool calls will be two separate entries. First for current<span class="punctuation">,</span> then for tomorrow\&#x27;s date.\n&lt;/think&gt;\n\n&#x27;<span class="punctuation">,</span> refusal=None<span class="punctuation">,</span> role=&#x27;assistant&#x27;<span class="punctuation">,</span> annotations=None<span class="punctuation">,</span> audio=None<span class="punctuation">,</span> function_call=None<span class="punctuation">,</span> tool_calls=<span class="punctuation">[</span>ChatCompletionMessageToolCall(id=&#x27;chatcmpl-tool<span class="number">-1e80</span>b27fc1534ac4bb3637de5e2d2cae&#x27;<span class="punctuation">,</span> function=Function(arguments=&#x27;<span class="punctuation">&#123;</span><span class="attr">&quot;location&quot;</span><span class="punctuation">:</span> <span class="string">&quot;San Francisco&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;unit&quot;</span><span class="punctuation">:</span> <span class="string">&quot;celsius&quot;</span><span class="punctuation">&#125;</span>&#x27;<span class="punctuation">,</span> name=&#x27;get_current_temperature&#x27;)<span class="punctuation">,</span> type=&#x27;function&#x27;)<span class="punctuation">,</span> ChatCompletionMessageToolCall(id=&#x27;chatcmpl-tool<span class="number">-600487</span>a6d6164fcc9e9b21336e01fa90&#x27;<span class="punctuation">,</span> function=Function(arguments=&#x27;<span class="punctuation">&#123;</span><span class="attr">&quot;location&quot;</span><span class="punctuation">:</span> <span class="string">&quot;San Francisco&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2024-10-01&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;unit&quot;</span><span class="punctuation">:</span> <span class="string">&quot;celsius&quot;</span><span class="punctuation">&#125;</span>&#x27;<span class="punctuation">,</span> name=&#x27;get_temperature_date&#x27;)<span class="punctuation">,</span> type=&#x27;function&#x27;)<span class="punctuation">]</span><span class="punctuation">,</span> reasoning_content=None)<span class="punctuation">,</span> stop_reason=None)<span class="punctuation">]</span><span class="punctuation">,</span> created=<span class="number">1746761516</span><span class="punctuation">,</span> model=&#x27;Qwen/Qwen3<span class="number">-1.7</span>B&#x27;<span class="punctuation">,</span> object=&#x27;chat.completion&#x27;<span class="punctuation">,</span> service_tier=None<span class="punctuation">,</span> system_fingerprint=None<span class="punctuation">,</span> usage=CompletionUsage(completion_tokens=<span class="number">383</span><span class="punctuation">,</span> prompt_tokens=<span class="number">412</span><span class="punctuation">,</span> total_tokens=<span class="number">795</span><span class="punctuation">,</span> completion_tokens_details=None<span class="punctuation">,</span> prompt_tokens_details=None)<span class="punctuation">,</span> prompt_logprobs=None)</span><br></pre></td></tr></table></figure>
<p>思考过程也可以让vllm解析出来</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve Qwen/Qwen3-1.7B --dtype half --enable-auto-tool-choice --tool-call-parser hermes  --enable-reasoning --reasoning-parser deepseek_r1</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ChatCompletion(id=&#x27;chatcmpl<span class="number">-173</span>d92e969ad42378cd54bba366993f9&#x27;<span class="punctuation">,</span> choices=<span class="punctuation">[</span>Choice(finish_reason=&#x27;tool_calls&#x27;<span class="punctuation">,</span> index=<span class="number">0</span><span class="punctuation">,</span> logprobs=None<span class="punctuation">,</span> message=ChatCompletionMessage(content=&#x27;\n\n&#x27;<span class="punctuation">,</span> refusal=None<span class="punctuation">,</span> role=&#x27;assistant&#x27;<span class="punctuation">,</span> annotations=None<span class="punctuation">,</span> audio=None<span class="punctuation">,</span> function_call=None<span class="punctuation">,</span> tool_calls=<span class="punctuation">[</span>ChatCompletionMessageToolCall(id=&#x27;chatcmpl-tool<span class="number">-3</span>c64e62980844b2993f17edd151a6862&#x27;<span class="punctuation">,</span> function=Function(arguments=&#x27;<span class="punctuation">&#123;</span><span class="attr">&quot;location&quot;</span><span class="punctuation">:</span> <span class="string">&quot;San Francisco&quot;</span><span class="punctuation">&#125;</span>&#x27;<span class="punctuation">,</span> name=&#x27;get_current_temperature&#x27;)<span class="punctuation">,</span> type=&#x27;function&#x27;)<span class="punctuation">,</span> ChatCompletionMessageToolCall(id=&#x27;chatcmpl-tool-de7be2853fd741cc8a8980fa7f62310b&#x27;<span class="punctuation">,</span> function=Function(arguments=&#x27;<span class="punctuation">&#123;</span><span class="attr">&quot;location&quot;</span><span class="punctuation">:</span> <span class="string">&quot;San Francisco&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2024-10-01&quot;</span><span class="punctuation">&#125;</span>&#x27;<span class="punctuation">,</span> name=&#x27;get_temperature_date&#x27;)<span class="punctuation">,</span> type=&#x27;function&#x27;)<span class="punctuation">]</span><span class="punctuation">,</span> reasoning_content=&#x27;\nOkay<span class="punctuation">,</span> the user is asking for the current temperature in San Francisco and the temperature tomorrow. Let me check the available functions.\n\nThere\&#x27;s get_current_temperature which requires a location and unit. The default unit is celsius. Then there\&#x27;s get_temperature_date which needs location<span class="punctuation">,</span> date<span class="punctuation">,</span> and unit. The date should be in Year-Month-Day format.\n\nSo for the current temperature<span class="punctuation">,</span> I\&#x27;ll use get_current_temperature with location <span class="string">&quot;San Francisco&quot;</span> and default unit. For tomorrow<span class="punctuation">,</span> I need to calculate the date. Today is September <span class="number">30</span><span class="punctuation">,</span> <span class="number">2024.</span> Tomorrow would be October <span class="number">1</span><span class="punctuation">,</span> <span class="number">2024.</span> So the date parameter would be <span class="string">&quot;2024-10-01&quot;</span>. \n\nI need to make two separate function calls. First for today<span class="punctuation">,</span> then for tomorrow. Make sure to specify the unit as celsius unless the user prefers Fahrenheit<span class="punctuation">,</span> but they didn\&#x27;t mention it<span class="punctuation">,</span> so default is okay.\n&#x27;)<span class="punctuation">,</span> stop_reason=None)<span class="punctuation">]</span><span class="punctuation">,</span> created=<span class="number">1746761680</span><span class="punctuation">,</span> model=&#x27;Qwen/Qwen3<span class="number">-1.7</span>B&#x27;<span class="punctuation">,</span> object=&#x27;chat.completion&#x27;<span class="punctuation">,</span> service_tier=None<span class="punctuation">,</span> system_fingerprint=None<span class="punctuation">,</span> usage=CompletionUsage(completion_tokens=<span class="number">254</span><span class="punctuation">,</span> prompt_tokens=<span class="number">412</span><span class="punctuation">,</span> total_tokens=<span class="number">666</span><span class="punctuation">,</span> completion_tokens_details=None<span class="punctuation">,</span> prompt_tokens_details=None)<span class="punctuation">,</span> prompt_logprobs=None)</span><br></pre></td></tr></table></figure>
<p>可见，think过程放到了<code>reasoning_content</code>字段，函数调用放到了<code>tool_calls</code>字段</p>
<h1>参考文献</h1>
<ol>
<li>vllm中文文档 <a target="_blank" rel="noopener" href="https://vllm.hyper.ai/docs/inference-and-serving/openai_compatible_server">https://vllm.hyper.ai/docs/inference-and-serving/openai_compatible_server</a></li>
<li>qwen3快速开始 <a target="_blank" rel="noopener" href="https://qwen.readthedocs.io/zh-cn/latest/deployment/vllm.html">https://qwen.readthedocs.io/zh-cn/latest/deployment/vllm.html</a></li>
<li>llm工具使用原理 <a target="_blank" rel="noopener" href="https://huggingface.co/blog/zh/unified-tool-use">https://huggingface.co/blog/zh/unified-tool-use</a></li>
<li>qwen函数调用原理 <a target="_blank" rel="noopener" href="https://qwen.readthedocs.io/zh-cn/latest/framework/function_call.html">https://qwen.readthedocs.io/zh-cn/latest/framework/function_call.html</a></li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://mylofty.github.io">JimmyDing</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://mylofty.github.io/2025/05/09/045d8c332459/">https://mylofty.github.io/2025/05/09/045d8c332459/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://mylofty.github.io" target="_blank">爱开源GoGo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ai/">ai</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/08/14/36b4391cdd6f/" title="解锁AI潜能：万字详解大语言模型提示工程的终极指南"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">解锁AI潜能：万字详解大语言模型提示工程的终极指南</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/06/11/fa22652bbbc5/" title="RAG应用"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-11</div><div class="title">RAG应用</div></div></a></div><div><a href="/2024/03/31/df8ae9e77565/" title="comfyui使用"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-31</div><div class="title">comfyui使用</div></div></a></div><div><a href="/2024/04/20/2f43d59ec67f/" title="huggingface镜像站使用"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-20</div><div class="title">huggingface镜像站使用</div></div></a></div><div><a href="/2024/05/10/981ace98feb5/" title="pytorch基础：FashionMNIST时装分类"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-10</div><div class="title">pytorch基础：FashionMNIST时装分类</div></div></a></div><div><a href="/2024/05/11/3148f0b756e9/" title="pytorch导学：使用bert实现分类任务"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-11</div><div class="title">pytorch导学：使用bert实现分类任务</div></div></a></div><div><a href="/2024/03/31/e135a5da70e3/" title="transformer详解"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-31</div><div class="title">transformer详解</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/notebook.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">JimmyDing</div><div class="author-info__description">种一棵树，最好的时间是十年前，其次是现在</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">32</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/mylofty"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎前来爱开源GoGo</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">环境搭建</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">命令行启动vllm</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">代码调用vllm</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">curl测试vllm</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">vllm函数调用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">参考文献</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/05/09/045d8c332459/" title="vllm使用教程-基于qwen模型"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vllm使用教程-基于qwen模型"/></a><div class="content"><a class="title" href="/2025/05/09/045d8c332459/" title="vllm使用教程-基于qwen模型">vllm使用教程-基于qwen模型</a><time datetime="2025-05-09T06:51:21.000Z" title="发表于 2025-05-09 14:51:21">2025-05-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/14/36b4391cdd6f/" title="解锁AI潜能：万字详解大语言模型提示工程的终极指南"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="解锁AI潜能：万字详解大语言模型提示工程的终极指南"/></a><div class="content"><a class="title" href="/2024/08/14/36b4391cdd6f/" title="解锁AI潜能：万字详解大语言模型提示工程的终极指南">解锁AI潜能：万字详解大语言模型提示工程的终极指南</a><time datetime="2024-08-14T06:51:21.000Z" title="发表于 2024-08-14 14:51:21">2024-08-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/11/fa22652bbbc5/" title="RAG应用"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RAG应用"/></a><div class="content"><a class="title" href="/2024/06/11/fa22652bbbc5/" title="RAG应用">RAG应用</a><time datetime="2024-06-11T06:51:21.000Z" title="发表于 2024-06-11 14:51:21">2024-06-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/07/225dc84728ab/" title="大模型意图选择"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型意图选择"/></a><div class="content"><a class="title" href="/2024/06/07/225dc84728ab/" title="大模型意图选择">大模型意图选择</a><time datetime="2024-06-07T06:51:21.000Z" title="发表于 2024-06-07 14:51:21">2024-06-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/11/3148f0b756e9/" title="pytorch导学：使用bert实现分类任务"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="pytorch导学：使用bert实现分类任务"/></a><div class="content"><a class="title" href="/2024/05/11/3148f0b756e9/" title="pytorch导学：使用bert实现分类任务">pytorch导学：使用bert实现分类任务</a><time datetime="2024-05-11T06:51:21.000Z" title="发表于 2024-05-11 14:51:21">2024-05-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/10/981ace98feb5/" title="pytorch基础：FashionMNIST时装分类"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="pytorch基础：FashionMNIST时装分类"/></a><div class="content"><a class="title" href="/2024/05/10/981ace98feb5/" title="pytorch基础：FashionMNIST时装分类">pytorch基础：FashionMNIST时装分类</a><time datetime="2024-05-10T06:51:21.000Z" title="发表于 2024-05-10 14:51:21">2024-05-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/26/111ea67534ab/" title="redis基础知识"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="redis基础知识"/></a><div class="content"><a class="title" href="/2024/04/26/111ea67534ab/" title="redis基础知识">redis基础知识</a><time datetime="2024-04-25T16:00:00.000Z" title="发表于 2024-04-26 00:00:00">2024-04-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/23/a07a83071c8a/" title="腹肌锻炼"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="腹肌锻炼"/></a><div class="content"><a class="title" href="/2024/04/23/a07a83071c8a/" title="腹肌锻炼">腹肌锻炼</a><time datetime="2024-04-23T06:51:21.000Z" title="发表于 2024-04-23 14:51:21">2024-04-23</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By JimmyDing</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>